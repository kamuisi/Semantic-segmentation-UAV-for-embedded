import torch
from fast_scnn import Fast_SCNN, PyramidPoolingModule
import onnx
import tensorflow as tf
from onnx_tf.backend import prepare
import numpy as np
from PIL import Image
import glob
import os

def representative_data_gen():
    image_dir = "images_png/"  
    image_paths = glob.glob(os.path.join(image_dir, "*.png"))  
    for img_path in image_paths[:100]: 
        img = Image.open(img_path).convert("RGB")
        img = img.resize((320, 320))
        arr = np.array(img).astype(np.float32) / 255.0  
        arr = np.transpose(arr, (2, 0, 1))
        arr = np.expand_dims(arr, axis=0) 
        yield [arr]


def export_onnx(pth_path, onnx_path, num_classes=8):
    model = Fast_SCNN(num_classes=num_classes)
    model.load_state_dict(torch.load(pth_path, map_location='cpu'))
    model.eval()
    model.gobal_feature[-1] = PyramidPoolingModule(128, pool_sizes=(1,))
    dummy_input = torch.randn(1, 3, 320, 320)
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        input_names=["input"],
        output_names=["output"],
        opset_version=13
    )
    print(f"âœ… Exported to {onnx_path}")

def onnx_to_tf(onnx_path, tf_path):
    onnx_model = onnx.load(onnx_path)
    onnx.checker.check_model(onnx_model)
    tf_rep = prepare(onnx_model)
    tf_rep.export_graph(tf_path)
    print(f"âœ… Converted to TensorFlow SavedModel at {tf_path}")

def tf_to_tflite(tf_path, tflite_path):
    converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    converter.representative_dataset = representative_data_gen
    tflite_model = converter.convert()
    with open(tflite_path, "wb") as f:
        f.write(tflite_model)
    print(f"âœ… Exported to {tflite_path}")

if __name__ == "__main__":
    onnx_path = "fast_scnn.onnx"
    tf_path = "fast_scnn_tf"
    tflite_path = "fast_scnn.tflite"

    export_onnx("fast_scnn_model.pth", onnx_path)
    onnx_to_tf(onnx_path, tf_path)
    tf_to_tflite(tf_path, tflite_path)
    print("ðŸŽ‰ All done! Your TFLite model is ready.")